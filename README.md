# Tutorial on Using TimeGAN to Generate Historical Stock Price Data
by Cydney Martell and Idris Sunmola

Generative Adversarial Networks (GANs) are a machine learning approach developed by Ian Goodfellow et al. in 2014 that use deep learning methods generate synthetic datasets. The overarching goal is to train a generator and discriminator in a competitive setting so the generator creates samples that the discriminator cannot distinguish from the real training data. GANs have been applied to generating high resolution images and in image to image translation. In addition to applications in image data, GANs have also been developed to generate synthetic time series datasets for applications in financial trading.  

In this tutorial, we will explain the TimeGAN architecture developed by Yoon et al. 2019 [1] and how it can be used to generate temporal time series data. We will then explain how to replicate TimeGAN and train it on our dataset to generate synthetic historical stock price dataset. The original manuscript can be found at the following link: https://papers.nips.cc/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf. 

Through this tutorial you will learn:
* The basics of TimeGAN architecture 
* How to set up the loss functions for TimeGAN 
* How to train the generator and discriminator 
* How to evaluate the quality of the synthetic time-series data generated by TimeGAN

## Tutorial Overview
1. Introduction to using GANs to generate temporal data
2. Historical stock prices dataset
3. Overview of TimeGAN architecture
4. Description of loss functions
5. How to train the generator
6. How to train the discriminator
8. Evaluation of training results
9. Conclusions and future applications

## Introduction to using GANs to generate temporal data
There is a need to generate synthetic time series data sets to augment datasets for applications in financial trading [2]. One of the major reasons financial training models fail in practice is because of the scarcity of historical time series data. Data augmentation of time series data sets could be especially useful to reduce backtest overfitting in models trained on historical time series data which is scarce [3]. It could also be useful in scenarios where privacy is an issue [3]. Developing a model to generate synthetic time series data is particularly challenging because the model needs to learn both the feature distributions at a specific time point and the dynamics of these features across time. 

### Previous attempts to generate synthetic temporal data
There have been other attempts to generate synthetic temporal data. In the manuscript, Yoon et.al summarize and compare their TimeGAN architecture to other models developed to generate synthetic time series data. They break these other methods down into two categories:
   1. Autoregressive Recurrent Network Approaches <br>
   
      Recurrent Neural Networks, specifically, long-short term memory paired with variational autoencoders have been used to generate high quality sequential  text data [1],[4]. While these models do well learning stepwise temporal dynamics, the main limitation is these models are learning the conditional output probability as described by the equation below. Therefore, these supervised models are inherently deterministic and not generative. This is a limitation in generating synthetic time series data because it doesnt allow for sampling from a learned training distribution so the generated sequences may not match the underlying training data. For these reasons, RNN based models for sequential data generation have worked well on highly structured text and speech data but this may not translate to less structured time series data. 
   <p align="center">  <img width="128" alt="image" src="https://user-images.githubusercontent.com/78554498/110225143-17924700-7ea8-11eb-8ef6-c81fcb3c9cd7.png"></p> <img align="right" img width="192" alt="image" src="https://user-images.githubusercontent.com/78554498/110226084-655f7d00-7eb1-11eb-95f2-da9ece1fd7bf.png">
    <br> 

   2. GAN Based Approaches <br>
   
   Another approach that has been taken is to directly apply GANs to temporal data. The first approach developed to tackle this problem was the C-RNN-GAN architecture which seeks to generate synthetic temporal data by using recurrent neural networks for the generator and discriminator. Then this approach was improved in upon in the RCGAN architecture by combining the recurrent GAN with additional conditional information as input. The additional information in the discriminator input can improve the quality and give some control of the GAN output. Schematics of these architectures are shown to the right in the image adapted from [5]. These models primarly learn based on the binary adversarial feedback, which the Yoon et al. hypothesize is not enough information to accurately capture the temporal dynamics of the data. Therefore the timeGAN architechture will be designed to address this limitation. 


### Advantages of using TimeGAN
In 2019, Yoon et al., developed the TimeGAN framework to help address the limitations with previous models explained above. This novel model combined the unsupervised adversarial learning present in GAN architecture with supervised training present in autoregressive models to generate realistic time-series data. The section of this tutorial on TimeGAN architechture will go more in depth into the characteristics of this model. 

Yoon et al. also investigated the performance of their TimeGAN model compared to other architectures for generating synthetic time series data. They tested these models on four different types of datasets (sines, stocks, energy, and events). They used four different types of data because they wanted to robustly investigate the utility of TimeGAN. They then evaluated the performance of their timeGAN to other approaches described above. The table below from Yoon et al. shows the performance of these models based on a discriminative and predictive score. The discriminative score indicates how similar the synthetic and real data are and the predictive score indicates how useful the synthetic data was compared to the real in training a predictive model. For both of these scores the lower the value the better. As you can see in the results from Yoon et al., the TimeGAN architecture produced the best synthetic data compared to the recurrent network and recurrent GAN models.  
<br> <p align="center">
<img width="626" alt="image" src="https://user-images.githubusercontent.com/78554498/110222700-c7ac8380-7e99-11eb-8eb8-6cc34a9895e9.png"> </p>

The figure from Yoon et al. shows dimensionality reduction analysis for real and synthetic data generated by the different models. You can see that the red (real) and blue (synthetic) points overlap and follow the same pattern more closesly in the timeGAN model than other models for both the sine (top row) and stock (bottom row) data. Therefore TimeGAN was able to best capture the important features of the real dataset in their synthetic data set. 
<p align="center"> <img width="1212" alt="image" src="https://user-images.githubusercontent.com/78554498/110227342-06a00080-7ebd-11eb-9eca-1ec90bcab162.png">
</p>


## Historical stock prices dataset
We trained our replicated TimeGAN architechture on a free dataset of end of day stock prices from https://www.quandl.com/databases/WIKIP/documentation. This is a large dataset that contains the end of the day stock prices collected between  July 6, 2015 to March 7, 2018 for a total of 590 observations per ticker. While this set contains data for 3,000 US companies,  we decided to select 86 tickers from this dataset for our replication of TimeGAN. The list of tickers that we used can be found in the file tickers.txt. 

The following image shows an example of the normalized historical ajusted close price data for 8 of the tickers. In these plots you can see there is a lot of variation in the data. There are also a in adjusted close price for the different tickers. The correlation coefficients for th e84 tickers range from -0.88 for CVS to 0.97 for LMT.  
![image](https://user-images.githubusercontent.com/78554498/110181326-23f7a080-7dd1-11eb-83ba-58be8b3b13c6.png)

Prior to training our TimeGAN model, we preprocessed the data following the methods of preprocess used by Yoon et. al. We used MinMaxScaler to scale the raw price series data between 0 and 1. We then created rolling window sequences with an overlap of 24 data points for each of the 86 tickers as used by Yoon et al. 
    
    #Obtains and stores the historical price dataset
    def get_wiki_prices():
        #Downloaded from https://www.quandl.com/api/v3/datatables/WIKI/PRICES?qopts.export=true&api_key=<API_KEY> and saved as 'wiki_stocks.csv'
      

        df = pd.read_csv('wiki_stocks.csv',
                         parse_dates=['date'],
                         index_col=['date', 'ticker'],
                         infer_datetime_format=True) 
        with pd.HDFStore('assets.h5') as store:
            store.put('quandl/wiki/prices', df)
            
    #Generates a list of ticker names      
    with open("tickers.txt") as file:
       tickers = [line.strip() for line in file]
   
    #Selects the adjusted close prices from the dataset for the 86 tickers of interest        
    def select_data():
        df = (pd.read_hdf('assets.h5', 'quandl/wiki/prices')
              .adj_close
              .unstack('ticker')
              .loc['2000':, tickers]
              .dropna())
            df.to_hdf(hdf_store, 'data/real')
    
    #Normalizes the stock price data to be between 0 and 1 
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(df).astype(np.float32)
    
    #Creates rolling window sequences
    seq_len = 24
    data = []
    for i in range(len(df) - seq_len):
         data.append(scaled_data[i:i + seq_len])

## Overview of TimeGAN architecture
Generative Adversarial Networks have come a long way since their initial unveiling by Ian Goodfellow of Google Brain at the 2016 NeurIPS conference. There have been countless iterations of GANs with just as many intricate architectures to match. GANs has become a staple in the machine learning arena, not only for its awe inspiring results, but also for its sheer utility.

The first generation of generative architectures had 2 components that literally “duked it out” in a sort of computational game of deception. One of its components, the discriminator, is nothing more than a deep supervised learning classifier that is well known and understood by anyone that has dabbled in any capacity in ML. The other component, the generator, is more of an enigma (,at least during its inauguration,) due to its relative complexity. The generator, unlike its discriminatory counterpart, takes in a vector drawn from a multivariate standard normal distribution. For the initiated, this is no different from the decoder of a variational autoencoder.

The goal is to map from a latent space back to the original domain. The generator aims to stump the discriminator by generating images that are so similar to the original class of images that they could have been drawn from the same dataset.

![gedl_0407](https://user-images.githubusercontent.com/20098178/110197863-ef590880-7e13-11eb-84c3-a94cb5f97cce.png)

Harkening back to what we said about the intricacies of the new crop of generative models, the TimeGan architecture is a testament to this fact. Consisting of four network modules, TimeGan is evenly split into an autoencoding component and adversarial component. With the autoencoder consisting of an embedding function and a recovery function. While the adversarial component comprises a sequence generator and a sequence discriminator.

The autoencoder’s embedding and recovery functions provide the mappings between the feature and latent space. Via lower-dimensional representations, the autoencoder allows the adversarial network to learn some underlying temporal dynamic of the data. Below is the embedding function e : 

![mathpix 2021-03-05 23-36-48](https://user-images.githubusercontent.com/20098178/110198066-50cda700-7e15-11eb-91bc-ba55ab3b2faf.png)

Below is the recovery function r :

![mathpix 2021-03-06 01-01-22](https://user-images.githubusercontent.com/20098178/110198375-a30fc780-7e17-11eb-87ed-c97e4f331774.png)

In the case of the generator, it first outputs into the embedding space, then produces the synthetic output directly in the feature space. Below is the generator function g :

![mathpix 2021-03-06 00-24-06](https://user-images.githubusercontent.com/20098178/110198176-1d3f4c80-7e16-11eb-80ef-993f64ed9518.png)

Below is the discrimination function d :

![mathpix 2021-03-06 01-04-59](https://user-images.githubusercontent.com/20098178/110198439-19142e80-7e18-11eb-8ebc-0467b3baa7b9.png)


![gan_arch](https://user-images.githubusercontent.com/20098178/110197437-44474f80-7e11-11eb-848c-87ac07044a69.png)




## Description of loss functions
The architecture embedding and recovery functions of the TimeGan architecture needs to facilitate accurate reconstruction of the original data from their latent representations. This provides the reversible mapping capabilities between the feature and latent spaces. As a result, the first objective function will be the reconstruction loss below:

![mathpix 2021-03-06 11-51-08](https://user-images.githubusercontent.com/20098178/110218901-d9822c80-7e81-11eb-922c-224222b5a9a1.png)

In order to generate the next synthetic vector, the generator (,the autoregressive part of the architecture,) takes in a synthetic embedding. This allows the unsupervised loss to be computed upon by the gradients. This allows the maximization of the discriminator and the minimization of the generator’s likelihood of providing accurate classifications for both the training data and synthetic output from the generator. The equation below makes this clear:

![mathpix 2021-03-06 13-33-22](https://user-images.githubusercontent.com/20098178/110218968-16e6ba00-7e82-11eb-9338-3d065ee90b63.png)

It will not be sufficient to rely only on the discriminator’s binary adversarial feedback. This is because we need more incentive for the generator to capture the conditional distribution in the data in a stepwise manner. An additional loss is needed to future penalize the model in the learning process. We need to apply a maximum likelihood to yield the supervised loss :

![mathpix 2021-03-06 13-34-42](https://user-images.githubusercontent.com/20098178/110219051-91173e80-7e82-11eb-963b-18adc55eb1e7.png)

![gan_loss](https://user-images.githubusercontent.com/20098178/110219087-b7d57500-7e82-11eb-94ee-de5b1e98b067.png)

## How to train the discriminator
For this section and the next, we will go over the two autoencoder, the two adversarial network elements, and the supervisor that makes the generator learn the temporal elements of the time-series data. First we will need to create RNNs with 24 GRU units each:

    def make_rnn(n_layers, hidden_units, output_units, name):
    return Sequential([GRU(units=hidden_units,
                           return_sequences=True,
                           name=f'GRU_{i + 1}') for i in range(n_layers)] +
                      [Dense(units=output_units,
                             activation='sigmoid',
                             name='OUT')], name=name)

After creating the autoencoder and instantiate the embedder and the recovery networks, we create the generator, the discriminator, and the supervisor:

    generator = make_rnn(n_layers=3, 
                     hidden_units=hidden_dim, 
                     output_units=hidden_dim, 
                     name='Generator')
    discriminator = make_rnn(n_layers=3, 
                         hidden_units=hidden_dim, 
                         output_units=1, 
                         name='Discriminator')
    supervisor = make_rnn(n_layers=2, 
                      hidden_units=hidden_dim, 
                      output_units=hidden_dim, 
                      name='Supervisor')

We then use the autoencoder to integrate both the embedder and recovery functions:

    H = embedder(X)
    X_tilde = recovery(H)
    autoencoder = Model(inputs=X,
                    outputs=X_tilde,
                    name='Autoencoder')
    autoencoder.summary()
    Model: "Autoencoder"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    RealData (InputLayer)        [(None, 24, 86)]           0         
    _________________________________________________________________
    Embedder (Sequential)        (None, 24, 24)            15864     
    _________________________________________________________________
    Recovery (Sequential)        (None, 24, 86)            12950     
    =================================================================
    Trainable params: 28,814

This sets us up to instantiate the optimizer and define the training steps:

    supervisor_optimizer = Adam()
    @tf.function
    def train_supervisor(x):
        with tf.GradientTape() as tape:
            h = embedder(x)
            h_hat_supervised = supervisor(h)
            g_loss_s = mse(h[:, 1:, :], h_hat_supervised[:, 1:, :])
        var_list = supervisor.trainable_variables
        gradients = tape.gradient(g_loss_s, var_list)
        supervisor_optimizer.apply_gradients(zip(gradients, var_list))
        return g_loss_s

## How to train the generator
This phase is the culmination of all four network components. We use all the loss functions and base componenets to achieve the joint learning of laten space embedding, transition, dynamics, and synthetic data generation.

TimeGan includes a moment loss to ensure that the generator truly creates viable time-series data. It does this by penalizing the model when the mean and variance of the synthetic data strays from the real data:

    def get_generator_moment_loss(y_true, y_pred):
    y_true_mean, y_true_var = tf.nn.moments(x=y_true, axes=[0])
    y_pred_mean, y_pred_var = tf.nn.moments(x=y_pred, axes=[0])
    g_loss_mean = tf.reduce_mean(tf.abs(y_true_mean - y_pred_mean))
    g_loss_var = tf.reduce_mean(tf.abs(tf.sqrt(y_true_var + 1e-6) - 
                                       tf.sqrt(y_pred_var + 1e-6)))
    return g_loss_mean + g_loss_var
    
As mentioned earlier, the training steps of the generator uses all four loss functions and combines all the network components to achieve the desired learning:

    @tf.function
    def train_generator(x, z):
        with tf.GradientTape() as tape:
            y_fake = adversarial_supervised(z)
            generator_loss_unsupervised = bce(y_true=tf.ones_like(y_fake),
                                              y_pred=y_fake)
            y_fake_e = adversarial_emb(z)
            generator_loss_unsupervised_e = bce(y_true=tf.ones_like(y_fake_e),
                                                y_pred=y_fake_e)
            h = embedder(x)
            h_hat_supervised = supervisor(h)
            generator_loss_supervised = mse(h[:, 1:, :], 
                                            h_hat_supervised[:, 1:, :])
            x_hat = synthetic_data(z)
            generator_moment_loss = get_generator_moment_loss(x, x_hat)
            generator_loss = (generator_loss_unsupervised +
                              generator_loss_unsupervised_e +
                              100 * tf.sqrt(generator_loss_supervised) +
                              100 * generator_moment_loss)
        var_list = generator.trainable_variables + supervisor.trainable_variables
        gradients = tape.gradient(generator_loss, var_list)
        generator_optimizer.apply_gradients(zip(gradients, var_list))
        return (generator_loss_unsupervised, generator_loss_supervised,
                generator_moment_loss)

## Evaluation of training results
After training the model, we were able to generate synthetic stock price data for 84 tickers. 

    generated_data = []
    for i in range(int(n_windows / batch_size)):
        Z_ = next(random_series)
        d = synthetic_data(Z_)
        generated_data.append(d)
     generated_data = np.array(np.vstack(generated_data))
     
     #Rescaled the generated data 
     generated_data = (scaler.inverse_transform(generated_data.reshape(-1, n_seq)).reshape(-1, seq_len, n_seq))
     
     #Stored the synthetic data 
     with pd.HDFStore(hdf_store) as store:
        store.put('data/synthetic', pd.DataFrame(generated_data.reshape(-1, n_seq),columns=tickers))

We then plotted this data to look at the comparison between the real and synthetic data generated by the TimeGAN model that we just trained. The following image shows an example of this plot for 8 tickers. The real data is shown in purple and the synthetic data is shown in black. Overall, it looks like the synthetic data does seem to capture some of the variability in the real data. Next we will take a closer look to truly evaluate the quality of this synthetic data. 

<p align="center"> <img width="950" alt="image" src="https://user-images.githubusercontent.com/78554498/110226138-4b726a00-7eb2-11eb-9d54-36c384ce2e0f.png"> </p>

Now we want to assess the quality of this synthetic data to evaluate our replication of the TimeGAN architechture. We will use the same criteria as Yoon et. al to evaluate the quality of the synthetic time series data generated by our model. The three criteria will will use are:
  1. Diversity
  2. Fidelity
  3. Usefulness 
 
### Diversity
First, we will investigate the diversity of the dataset. The main question we are asking here is: does the synthetic data distribution match the distribution of the real data? We assess diversity by using a qualitative approach of dimensionality reduction. We used two different methods: principle component analysis (PCA) and t-distributed stochastic neighbor embedding (t-SNE). 

    #Imports the Necessary Libraries for TSNE and PCA
    from sklearn.manifold import TSNE
    from sklearn.decomposition import PCA
    
    #Does two component PCA on the real and the synthetic data
    pca = PCA(n_components=2)
    pca.fit(real_sample_2d)
    pca_real = (pd.DataFrame(pca.transform(real_sample_2d)).assign(Data='Real'))
    pca_synthetic = (pd.DataFrame(pca.transform(synthetic_sample_2d)).assign(Data='Synthetic'))
    pca_result = pca_real.append(pca_synthetic).rename(columns={0: '1st Component', 1: '2nd Component'})


    #Does t-SNE on the real and synthetic data 
    tsne_data = np.concatenate((real_sample_2d, synthetic_sample_2d), axis=0)
    tsne = TSNE(n_components=2, verbose=1, perplexity=40)
    tsne_result = tsne.fit_transform(tsne_data)
 
We then plotted the results of the dimensionality reduction analysis to look at the overlap of the real and the synthetic data. The following plots display the results of dimensionality reduction. The results of PCA are on the left and t-SNE is one the right with the real data is shown in purple and the synthetic data shown in black. In both methods of dimensionality reduction, you can see that there is overlap between the real and synthetic data. This indicates that our replicated TimeGAN model was able to generate synthetic historical price data that captures the important features of the real training data. 
<p align="center"> <img width="824" alt="image" src="https://user-images.githubusercontent.com/78554498/110226466-2fbc9300-7eb5-11eb-90a9-cb09c7c48e71.png"> </p>

### Fidelity 
Next, we will investigate the fidelity of the dataset. Primarly we want to know, is the synthetic price series indistinguishable from the real data. To test this we trained a classifier to distinguish between real and fake data and then evaluated the performance of this classifier. If the synthetic data has high fidelity then the classifier should be unable to distinguish between the datasets and would have a low performance score. 

First, we processed the real and synthetic data and separated it into a training set and a test set. 

    real_data = get_real_data()
    real_data = np.array(real_data)[:len(synthetic_data)]
    
    #Separates the dataset to be 80% training data and 20% testing data
    n_series = real_data.shape[0]
    idx = np.arange(n_series)
    n_train = int(.8*n_series)
    train_idx = idx[:n_train]
    test_idx = idx[n_train:]

We then created a time-series classifier to distinguish between real and synthetic data. The image shows a summary of the classifier we used 

    ts_classifier = Sequential([GRU(6, input_shape=(24, 86), name='GRU'), Dense(1, activation='sigmoid', name='OUT')], name='Time_Series_Classifier')
    ts_classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC(name='AUC'), 'accuracy'])
    ts_classifier.summary()
 <p align="center">   <img width="652" alt="image" src="https://user-images.githubusercontent.com/78554498/110227522-e07b6000-7ebe-11eb-9440-e3a30c638c65.png"> </p>


We then trained the classifier on a training dataset composed of both real and synthetic data for a total fo 250 epochs. The performance of the classifier was then tracked over the epochs by looking at the AUC under the ROC curve and the accuracy. 

      result = ts_classifier.fit(x=train_data,y=train_labels, validation_data=(test_data, test_labels), epochs=250, batch_size=128, verbose=0)
      ts_classifier.evaluate(x=test_data, y=test_labels)
    
The accuracy of the classifier and the area under the ROC curve was then plotted and is shown below. The accuracy vs epoch is shown on the left, after 250 epochs the accuracy was 0.39 with a classification error of 61% for the test data. The AUC is on the right and after 250 epochs the AUC was 0.11 for the test data. These metrics of accuracy and AUC are both low, indicating that the time series classifier we trained was unable to distinguish between the real and the synthetic data. 

 <p align="center">  <img width="918" alt="image" src="https://user-images.githubusercontent.com/78554498/110226831-e6217780-7eb7-11eb-8e23-27d745e1473b.png"> </p>

### Usefulness
Lastly, we will look at the usefulness of the synthetic data. So, we want to know is the synthetic data series as useful as the real data for solving a predictive task. To do this we generated a sequence prediction model, as shown below, to predict the next time step. The model uses the adam optimizer to minimize the mean absolute error. To compare the synthetic and real data, we will then train this model either on synthetic data or on real data. We will then test the model on a subset of real data. 

    #Sequence prediction model
    def get_model():
        model = Sequential([GRU(12, input_shape=(seq_len-1, n_seq)), Dense(86)])
        model.compile(optimizer=Adam(), loss=MeanAbsoluteError(name='MAE'))
        return model
        
 One model was trained on synthetic data and tested on real data using the code shown below. The model was trained over 100 epochs.
 
    #Training on synthetic, testing on real
    ts_regression = get_model()
    synthetic_result = ts_regression.fit(x=synthetic_train,y=synthetic_label, validation_data=(real_test_data, real_test_label),epochs=100,batch_size=128,verbose=0)
 
 Another model was trained on real data and tested on real data. The model was trained over 100 epochs.  
 
     ts_regression = get_model()
     real_result = ts_regression.fit(x=real_train_data,y=real_train_label,validation_data=(real_test_data, real_test_label),epochs=100,batch_size=128,verbose=0)
 
The performance of these two models was tracked over the epochs and then plotted as shown below. This image shows the log mean absolute error for the model traind on synthetic tested on real (left) and the model trained on real and tested on synthetic (right). After 100 epochs the mean absolute error for the model trained on synthetic was 0.06 and the mean absolute error for the model trained on real data was 0.15. This result showed the synthetic data may be useful. For this specific task of predicting the next time step for 84 tickers the model trained on synthetic timeGAN generated data performed slightly better than the same model trained on real data based on the mean absolute error. 
 
 <p align="center">  <img width="935" alt="image" src="https://user-images.githubusercontent.com/78554498/110227211-9b096380-7ebb-11eb-8e49-dc8fbcc6eda5.png"> </p>



## Conclusions and future applications

We replicated the TimeGAN architecture and train it on a different dataset of historical stock price than the authors. The data that we generated using code adapted from Yoon et al. generated high quality synthetic stock price series for 84 tickers. This synthetic data seemed to capture the features of the real data, was indistinguishable from the real data, and training a model on the synthetic data was more useful in solving a predictive task than the real data. These results along with the results in the paper suggest that timeGAN is a promising approach to use for generating synthetic time series data. 

## References
[1] https://papers.nips.cc/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf <br>
[2] https://arxiv.org/pdf/2002.12478.pdf <br>
[3] http://www.blackarbs.com/synthetic-data <br>
[4] https://arxiv.org/pdf/1308.0850.pdf <br>
[5] https://openreview.net/pdf?id=whySRc6f5g_<br>
