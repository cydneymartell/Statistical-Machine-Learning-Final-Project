# Tutorial on Using TimeGAN to Generate Historical Stock Price Data
by Cydney Martell and Idris Sunmola

Generative Adversarial Networks (GANs) are a machine learning approach developed by Ian Goodfellow et al. in 2014 that use deep learning methods generate synthetic datasets. The overarching goal is to train a generator and discriminator in a competitive setting so the generator creates samples that the discriminator cannot distinguish from the real training data. GANs have been applied to generating high resolution images and in image to image translation. In addition to applications in image data, GANs have also been developed to generate synthetic time series datasets for applications in financial trading.  

In this tutorial, we will explain the TimeGAN architecture developed by Yoon et al. 2019 [1] and how it can be used to generate temporal time series data. We will then explain how to replicate TimeGAN and train it on our dataset to generate synthetic historical stock price dataset. The original manuscript can be found at the following link: https://papers.nips.cc/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf. 

Through this tutorial you will learn:
* The basics of TimeGAN architecture 
* How to set up the loss functions for TimeGAN 
* How to train the generator and discriminator 
* How to evaluate the quality of the synthetic time-series data generated by TimeGAN

## Tutorial Overview
1. Introduction to using GANs to generate temporal data
2. Historical stock prices dataset
3. Overview of TimeGAN architecture
4. Description of loss functions
5. How to train the generator
6. How to train the discriminator
8. Evaluation of training results
9. Conclusions and future applications

## Introduction to using GANs to generate temporal data
There is a need to generate synthetic time series data sets to augment datasets for applications in financial trading [2]. One of the major reasons financial training models fail in practice is because of the scarcity of historical time series data. Data augmentation of time series data sets could be especially useful to reduce backtest overfitting in models trained on historical time series data which is scarce [3]. It could also be useful in scenarios where privacy is an issue [3]. Developing a model to generate synthetic time series data is particularly challenging because the model needs to learn both the feature distributions at a specific time point and the dynamics of these features across time. 

### Previous attempts to generate synthetic temporal data
There have been other attempts to generate synthetic temporal data. In the manuscript, Yoon et.al summarize and compare their TimeGAN architecture to other models developed to generate synthetic time series data. They break these other methods down into two categories:
  1. Autoregressive Recurrent Network Approaches <br>
   Recurrent Neural Networks, specifically, long-short term memory paired with variational autoencoders have been used to generate high quality sequential text data [1],[4]. These models are only learning variability from the conditional output probability as described by the following equation: <br> 
 <p align="center">  <img width="128" alt="image" src="https://user-images.githubusercontent.com/78554498/110225143-17924700-7ea8-11eb-8ef6-c81fcb3c9cd7.png"></p> <br>
Therefore these supervised models are inherently deterministic and not generative. This is a limitation in generating synthetic time series data.  For these reasons, RNN based models for sequential data generation have worked well on highly structured text and speech data but this may not translate to less structured time series data. 
 

  2. GAN Based Approaches <br>
  Another approach that has been taken is to directly apply GANs to temporal data. The first approach developed to tackle this problem was the C-RNN-GAN architecture which seeks to capture the temporal aspects of the data by using recurrent neural networks for the generator and discriminator. Then this approach was improved in upon in the RCGAN architecture by combining the recurrent GAN with additional conditional information as input. 


### Advantages of using TimeGAN
In 2019, Yoon et al., developed the TimeGAN framework to help address the limitations with previous models explained above. This novel model combined the unsupervised adversarial learning present in GAN architecture with supervised training present in autoregressive models to generate realistic time-series data. The section of this tutorial on TimeGAN architechture will go more in depth into the characteristics of this model. 

Yoon et al. also investigated the performance of their TimeGAN model compared to other architectures for generating synthetic time series data. They tested these models on four different types of datasets (sines, stocks, energy, and events) and then evaluated the performance of these models. The table below from Yoon et al. shows the performance of these models based on a discriminative and predictive score. The discriminative score indicates how similar the synthetic and real data are and the predictive score indicates how useful the synthetic data was compared to the real in training a predictive model. For both of these scores the lower the value the better. As you can see in the results from Yoon et al., the TimeGAN architecture produced the best synthetic data compared to the recurrent network and recurrent GAN models.  
<br> <p align="center">
<img width="626" alt="image" src="https://user-images.githubusercontent.com/78554498/110222700-c7ac8380-7e99-11eb-8eb8-6cc34a9895e9.png"> </p>



**FINISH THIS**

## Historical stock prices dataset
We trained our replicated TimeGAN architechture on a free dataset of end of day stock prices from https://www.quandl.com/databases/WIKIP/documentation. This is a large dataset that contains the end of the day stock prices collected between  July 6, 2015 to March 7, 2018 for a total of 590 observations per ticker. While this set contains data for 3,000 US companies,  we decided to select 86 tickers from this dataset for our replication of TimeGAN. The list of tickers that we used can be found in the file tickers.txt. 

The following image shows an example of the normalized historical ajusted close price data for 8 of the tickers. In these plots you can see there is a lot of variation in the data. There are also a in adjusted close price for the different tickers. The correlation coefficients for th e84 tickers range from -0.88 for CVS to 0.97 for LMT.  
![image](https://user-images.githubusercontent.com/78554498/110181326-23f7a080-7dd1-11eb-83ba-58be8b3b13c6.png)

Prior to training our TimeGAN model, we preprocessed the data following the methods of preprocess used by Yoon et. al. We used MinMaxScaler to scale the raw price series data between 0 and 1. We then created rolling window sequences with an overlap of 24 data points for each of the 86 tickers as used by Yoon et al. 
    
    #Obtains and stores the historical price dataset
    def get_wiki_prices():
        #Downloaded from https://www.quandl.com/api/v3/datatables/WIKI/PRICES?qopts.export=true&api_key=<API_KEY> and saved as 'wiki_stocks.csv'
      

        df = pd.read_csv('wiki_stocks.csv',
                         parse_dates=['date'],
                         index_col=['date', 'ticker'],
                         infer_datetime_format=True) 
        with pd.HDFStore('assets.h5') as store:
            store.put('quandl/wiki/prices', df)
            
    #Generates a list of ticker names      
    with open("tickers.txt") as file:
       tickers = [line.strip() for line in file]
   
    #Selects the adjusted close prices from the dataset for the 86 tickers of interest        
    def select_data():
        df = (pd.read_hdf('assets.h5', 'quandl/wiki/prices')
              .adj_close
              .unstack('ticker')
              .loc['2000':, tickers]
              .dropna())
            df.to_hdf(hdf_store, 'data/real')
    
    #Normalizes the stock price data to be between 0 and 1 
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(df).astype(np.float32)
    
    #Creates rolling window sequences
    seq_len = 24
    data = []
    for i in range(len(df) - seq_len):
         data.append(scaled_data[i:i + seq_len])

## Overview of TimeGAN architecture
Generative Adversarial Networks have come a long way since their initial unveiling by Ian Goodfellow of Google Brain at the 2016 NeurIPS conference. There have been countless iterations of GANs with just as many intricate architectures to match. GANs has become a staple in the machine learning arena, not only for its awe inspiring results, but also for its sheer utility.

The first generation of generative architectures had 2 components that literally “duked it out” in a sort of computational game of deception. One of its components, the discriminator, is nothing more than a deep supervised learning classifier that is well known and understood by anyone that has dabbled in any capacity in ML. The other component, the generator, is more of an enigma (,at least during its inauguration,) due to its relative complexity. The generator, unlike its discriminatory counterpart, takes in a vector drawn from a multivariate standard normal distribution. For the initiated, this is no different from the decoder of a variational autoencoder.

The goal is to map from a latent space back to the original domain. The generator aims to stump the discriminator by generating images that are so similar to the original class of images that they could have been drawn from the same dataset.

![gedl_0407](https://user-images.githubusercontent.com/20098178/110197863-ef590880-7e13-11eb-84c3-a94cb5f97cce.png)

Harkening back to what we said about the intricacies of the new crop of generative models, the TimeGan architecture is a testament to this fact. Consisting of four network modules, TimeGan is evenly split into an autoencoding component and adversarial component. With the autoencoder consisting of an embedding function and a recovery function. While the adversarial component comprises a sequence generator and a sequence discriminator.

The autoencoder’s embedding and recovery functions provide the mappings between the feature and latent space. Via lower-dimensional representations, the autoencoder allows the adversarial network to learn some underlying temporal dynamic of the data. Below is the embedding function e : 

![mathpix 2021-03-05 23-36-48](https://user-images.githubusercontent.com/20098178/110198066-50cda700-7e15-11eb-91bc-ba55ab3b2faf.png)

Below is the recovery function r :

![mathpix 2021-03-06 01-01-22](https://user-images.githubusercontent.com/20098178/110198375-a30fc780-7e17-11eb-87ed-c97e4f331774.png)

In the case of the generator, it first outputs into the embedding space, then produces the synthetic output directly in the feature space. Below is the generator function g :

![mathpix 2021-03-06 00-24-06](https://user-images.githubusercontent.com/20098178/110198176-1d3f4c80-7e16-11eb-80ef-993f64ed9518.png)

Below is the discrimination function d :

![mathpix 2021-03-06 01-04-59](https://user-images.githubusercontent.com/20098178/110198439-19142e80-7e18-11eb-8ebc-0467b3baa7b9.png)


![gan_arch](https://user-images.githubusercontent.com/20098178/110197437-44474f80-7e11-11eb-848c-87ac07044a69.png)




## Description of loss functions
The architecture embedding and recovery functions of the TimeGan architecture needs to facilitate accurate reconstruction of the original data from their latent representations. This provides the reversible mapping capabilities between the feature and latent spaces. As a result, the first objective function will be the reconstruction loss below:

![mathpix 2021-03-06 11-51-08](https://user-images.githubusercontent.com/20098178/110218901-d9822c80-7e81-11eb-922c-224222b5a9a1.png)

In order to generate the next synthetic vector, the generator (,the autoregressive part of the architecture,) takes in a synthetic embedding. This allows the unsupervised loss to be computed upon by the gradients. This allows the maximization of the discriminator and the minimization of the generator’s likelihood of providing accurate classifications for both the training data and synthetic output from the generator. The equation below makes this clear:

![mathpix 2021-03-06 13-33-22](https://user-images.githubusercontent.com/20098178/110218968-16e6ba00-7e82-11eb-9338-3d065ee90b63.png)

It will not be sufficient to rely only on the discriminator’s binary adversarial feedback. This is because we need more incentive for the generator to capture the conditional distribution in the data in a stepwise manner. An additional loss is needed to future penalize the model in the learning process. We need to apply a maximum likelihood to yield the supervised loss :

![mathpix 2021-03-06 13-34-42](https://user-images.githubusercontent.com/20098178/110219051-91173e80-7e82-11eb-963b-18adc55eb1e7.png)

![gan_loss](https://user-images.githubusercontent.com/20098178/110219087-b7d57500-7e82-11eb-94ee-de5b1e98b067.png)

## How to train the discriminator
For this section and the next, we will go over the two autoencoder, the two adversarial network elements, and the supervisor that makes the generator learn the temporal elements of the time-series data. First we will need to create RNNs with 24 GRU units each:

    def make_rnn(n_layers, hidden_units, output_units, name):
    return Sequential([GRU(units=hidden_units,
                           return_sequences=True,
                           name=f'GRU_{i + 1}') for i in range(n_layers)] +
                      [Dense(units=output_units,
                             activation='sigmoid',
                             name='OUT')], name=name)

After creating the autoencoder and instantiate the embedder and the recovery networks, we create the generator, the discriminator, and the supervisor:

    generator = make_rnn(n_layers=3, 
                     hidden_units=hidden_dim, 
                     output_units=hidden_dim, 
                     name='Generator')
    discriminator = make_rnn(n_layers=3, 
                         hidden_units=hidden_dim, 
                         output_units=1, 
                         name='Discriminator')
    supervisor = make_rnn(n_layers=2, 
                      hidden_units=hidden_dim, 
                      output_units=hidden_dim, 
                      name='Supervisor')

We then use the autoencoder to integrate both the embedder and recovery functions:

    H = embedder(X)
    X_tilde = recovery(H)
    autoencoder = Model(inputs=X,
                    outputs=X_tilde,
                    name='Autoencoder')
    autoencoder.summary()
    Model: "Autoencoder"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    RealData (InputLayer)        [(None, 24, 86)]           0         
    _________________________________________________________________
    Embedder (Sequential)        (None, 24, 24)            15864     
    _________________________________________________________________
    Recovery (Sequential)        (None, 24, 86)            12950     
    =================================================================
    Trainable params: 28,814

This sets us up to instantiate the optimizer and define the training steps:

    supervisor_optimizer = Adam()
    @tf.function
    def train_supervisor(x):
        with tf.GradientTape() as tape:
            h = embedder(x)
            h_hat_supervised = supervisor(h)
            g_loss_s = mse(h[:, 1:, :], h_hat_supervised[:, 1:, :])
        var_list = supervisor.trainable_variables
        gradients = tape.gradient(g_loss_s, var_list)
        supervisor_optimizer.apply_gradients(zip(gradients, var_list))
        return g_loss_s

## How to train the generator
This phase is the culmination of all four network components. We use all the loss functions and base componenets to achieve the joint learning of laten space embedding, transition, dynamics, and synthetic data generation.

TimeGan includes a moment loss to ensure that the generator truly creates viable time-series data. It does this by penalizing the model when the mean and variance of the synthetic data strays from the real data:

    def get_generator_moment_loss(y_true, y_pred):
    y_true_mean, y_true_var = tf.nn.moments(x=y_true, axes=[0])
    y_pred_mean, y_pred_var = tf.nn.moments(x=y_pred, axes=[0])
    g_loss_mean = tf.reduce_mean(tf.abs(y_true_mean - y_pred_mean))
    g_loss_var = tf.reduce_mean(tf.abs(tf.sqrt(y_true_var + 1e-6) - 
                                       tf.sqrt(y_pred_var + 1e-6)))
    return g_loss_mean + g_loss_var
    
As mentioned earlier, the trianing steps of the generator uses all four loss functions and combines all the network components to achieve the desired learning:

    @tf.function
    def train_generator(x, z):
        with tf.GradientTape() as tape:
            y_fake = adversarial_supervised(z)
            generator_loss_unsupervised = bce(y_true=tf.ones_like(y_fake),
                                              y_pred=y_fake)
            y_fake_e = adversarial_emb(z)
            generator_loss_unsupervised_e = bce(y_true=tf.ones_like(y_fake_e),
                                                y_pred=y_fake_e)
            h = embedder(x)
            h_hat_supervised = supervisor(h)
            generator_loss_supervised = mse(h[:, 1:, :], 
                                            h_hat_supervised[:, 1:, :])
            x_hat = synthetic_data(z)
            generator_moment_loss = get_generator_moment_loss(x, x_hat)
            generator_loss = (generator_loss_unsupervised +
                              generator_loss_unsupervised_e +
                              100 * tf.sqrt(generator_loss_supervised) +
                              100 * generator_moment_loss)
        var_list = generator.trainable_variables + supervisor.trainable_variables
        gradients = tape.gradient(generator_loss, var_list)
        generator_optimizer.apply_gradients(zip(gradients, var_list))
        return (generator_loss_unsupervised, generator_loss_supervised,
                generator_moment_loss)

## Evaluation of training results
After training the model, we were able to generate synthetic stock price data for 84 tickers. 

    generated_data = []
    for i in range(int(n_windows / batch_size)):
        Z_ = next(random_series)
        d = synthetic_data(Z_)
        generated_data.append(d)
     generated_data = np.array(np.vstack(generated_data))
     
     #Rescaled the generated data 
     generated_data = (scaler.inverse_transform(generated_data.reshape(-1, n_seq)).reshape(-1, seq_len, n_seq))
     
     #Stored the synthetic data 
     with pd.HDFStore(hdf_store) as store:
        store.put('data/synthetic', pd.DataFrame(generated_data.reshape(-1, n_seq),columns=tickers))

Now we want to assess the quality of this synthetic data to evaluate our replication of the TimeGAN architechture. We will use the same criteria as Yoon et. al to evaluate the quality of the synthetic time series data generated by our model. The three criteria will will use are:
  1. Diversity
  2. Fidelity
  3. Usefulness 
 
### Diversity
First, we will investigate the diversity of the dataset. The main question we are asking here is: does the synthetic data distribution match the distribution of the real data? We assess diversity by using a qualitative approach of dimensionality reduction. We used two different methods: principle component analysis (PCA) and t-distributed stochastic neighbor embedding (t-SNE). 

    #Imports the Necessary Libraries for TSNE and PCA
    from sklearn.manifold import TSNE
    from sklearn.decomposition import PCA
    
    #Does two component PCA on the real and the synthetic data
    pca = PCA(n_components=2)
    pca.fit(real_sample_2d)
    pca_real = (pd.DataFrame(pca.transform(real_sample_2d)).assign(Data='Real'))
    pca_synthetic = (pd.DataFrame(pca.transform(synthetic_sample_2d)).assign(Data='Synthetic'))
    pca_result = pca_real.append(pca_synthetic).rename(columns={0: '1st Component', 1: '2nd Component'})


    #Does t-SNE on the real and synthetic data 
    tsne_data = np.concatenate((real_sample_2d, synthetic_sample_2d), axis=0)
    tsne = TSNE(n_components=2, verbose=1, perplexity=40)
    tsne_result = tsne.fit_transform(tsne_data)
 
 We then plotted the results of the dimensionality reduction analysis. 
 
    #Plots the PCA Results
    fig, axes = plt.subplots(ncols=2, figsize=(14, 5))
    sns.scatterplot(x='1st Component', y='2nd Component', data=pca_result, hue='Data', style='Data', ax=axes[0])
    sns.despine()
    axes[0].set_title('PCA Result')
    
    #Plots the t-SNE results
    sns.scatterplot(x='X', y='Y', data=tsne_result, hue='Data', style='Data', ax=axes[1])
    sns.despine()
    for i in [0, 1]:
        axes[i].set_xticks([])
        axes[i].set_yticks([])
    axes[1].set_title('t-SNE Result')
    
    fig.suptitle('Assessing Diversity: Qualitative Comparison of Real and Synthetic Data Distributions', fontsize=14)
    fig.tight_layout()
    fig.subplots_adjust(top=.88);
    

### Fidelity 
Next, we will investigate the fidelity of the dataset. Primarly we want to know, is the synthetic price series indistinguishable from the real data. To test this we trained a classifier to distinguish between real and fake data and then evaluated the performance of this classifier. If the synthetic data has high fidelity then the classifier should be unable to distinguish between the datasets and would have a low performance score. 

First, we had to process the data to separate it into a training set and a test set. 

    real_data = get_real_data()
    real_data = np.array(real_data)[:len(synthetic_data)]
    
    #Separates the dataset to be 80% training data and 20% testing data
    n_series = real_data.shape[0]
    idx = np.arange(n_series)
    n_train = int(.8*n_series)
    train_idx = idx[:n_train]
    test_idx = idx[n_train:]
We then trained a classifier 

### Usefulness
Lastly, we will look at the usefulness of the synthetic data. So, we want to know is the synthetic data series as useful as the real data for solving a predictive task. 


## Conclusions and future applications

## References
[1] https://papers.nips.cc/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf <br>
[2] https://arxiv.org/pdf/2002.12478.pdf <br>
[3] http://www.blackarbs.com/synthetic-data
[4] https://arxiv.org/pdf/1308.0850.pdf
